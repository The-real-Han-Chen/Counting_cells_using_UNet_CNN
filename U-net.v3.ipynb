{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet for image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: loading required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# set seeds to ensure repeatability of results\n",
    "from numpy.random import seed\n",
    "seed(101)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# import cv2\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(101)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Activation\n",
    "from tensorflow.keras.layers import concatenate, BatchNormalization, Conv2DTranspose\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import skimage\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"numpy versions is: \", np.__version__)\n",
    "print(\"pandas versions is: \", pd.__version__)\n",
    "print(\"tensorflow versions is: \", tf.__version__)\n",
    "print(\"skimage versions is: \", skimage.__version__)\n",
    "print(\"matplotlib versions is: \", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: examine the number of GPUs (CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3: list all image files and load them, resize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import glob as gb\n",
    "cell_img_list = gb.glob(\"./dataset02/*cells.png\")\n",
    "dots_img_list = gb.glob(\"./dataset02/*dots.png\")\n",
    "(IMG_HEIGHT, IMG_WIDTH) = imread(dots_img_list[0]).shape\n",
    "\n",
    "PADDING = 40\n",
    "# NUM_TEST_IMAGES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =====================    \n",
    "# Create X_test\n",
    "# ===================== \n",
    "\n",
    "# create an empty matrix\n",
    "# IMG_CHANNELS = 3; \n",
    "IMG_CHANNELS = 1;    # use gray scale images\n",
    "\n",
    "# X_test = np.zeros((len(cell_img_list), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "X_test = np.zeros((len(cell_img_list), IMG_HEIGHT, IMG_WIDTH)) \n",
    "Y_test = np.zeros((len(dots_img_list), IMG_HEIGHT, IMG_WIDTH)) \n",
    "\n",
    "for i,j in enumerate(cell_img_list):\n",
    "    X_test[i,:,:] = imread(cell_img_list[i], as_gray = True)\n",
    "    Y_test[i,:,:] = imread(dots_img_list[i])     # already gray\n",
    "print(X_test.shape)\n",
    "(a1,b1,c1) = (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =====================    \n",
    "# Resizing X_test\n",
    "# ===================== \n",
    "\n",
    "# new size: square\n",
    "IMG_HEIGHT_input  = 512\n",
    "IMG_WIDTH_input   = 512\n",
    "IMG_HEIGHT_output = 512\n",
    "IMG_WIDTH_output  = 512\n",
    "\n",
    "X_test_2 = np.zeros((len(cell_img_list), IMG_HEIGHT_input, IMG_WIDTH_input,   IMG_CHANNELS))\n",
    "Y_test_2 = np.zeros((len(dots_img_list), IMG_HEIGHT_output, IMG_WIDTH_output, IMG_CHANNELS)) \n",
    "\n",
    "for i in range(len(cell_img_list)):\n",
    "    X_test_2[i,:,:,0] = resize(X_test[i,:,:], (IMG_HEIGHT_input, IMG_WIDTH_input  ))\n",
    "    Y_test_2[i,:,:,0] = resize(Y_test[i,:,:], (IMG_HEIGHT_output, IMG_WIDTH_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skip to step 6 if no training is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots(1,2, figsize = (10,5))\n",
    "ax0[0].imshow(resize(X_test[0,:,:],(512,512)))\n",
    "ax0[1].imshow(resize(Y_test[0,:,:],(512,512)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: setting up the model, Wendi Xie's work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "weight_decay = 1e-5\n",
    "\n",
    "def get_crop_shape(target, refer):\n",
    "    # width, the 3rd dimension\n",
    "    cw = (target.get_shape()[2] - refer.get_shape()[2])\n",
    "    assert (cw >= 0)\n",
    "    if cw % 2 != 0:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "    else:\n",
    "        cw1, cw2 = int(cw/2), int(cw/2)\n",
    "    \n",
    "    # height, the 2nd dimension\n",
    "    ch = (target.get_shape()[1] - refer.get_shape()[1])\n",
    "    assert (ch >= 0)\n",
    "    if ch % 2 != 0:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "    else:\n",
    "        ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "    return (ch1, ch2), (cw1, cw2)\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\n",
    "               kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\n",
    "               kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPool2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPool2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPool2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPool2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "\n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "\n",
    "#     u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c4)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], \n",
    "                  outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_img  = tf.keras.layers.Input((IMG_HEIGHT_input, IMG_WIDTH_input, IMG_CHANNELS))\n",
    "model_unet = get_unet(Input_img, n_filters = 16, dropout = 0.1, batchnorm = True)\n",
    "\n",
    "model_unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Model(inputs = [X_test_2], outputs = [Y_test_2])\n",
    "filepath = \"model.h5\"\n",
    "\n",
    "earlystopper = EarlyStopping(patience=15, verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error',\n",
    "                             verbose=1, mode='min')\n",
    "\n",
    "callbacks_list = [earlystopper, checkpoint]\n",
    "callbacks_list = [earlystopper]\n",
    "model_unet.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "history = model_unet.fit(X_test_2, Y_test_2,\n",
    "                         validation_split=0.15, batch_size=1, \n",
    "                         epochs=10, callbacks=callbacks_list\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 5: saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model_unet,\"U-net.model.v3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 6: loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet = tf.keras.models.load_model(\"U-net.model.v3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# num_list = np.arange(0, 8)\n",
    "# num_list = np.arange(-8, 0)\n",
    "num_list = np.random.randint(102, size=8)\n",
    "\n",
    "results = model_unet.predict(X_test_2[num_list,:,:,:])\n",
    "img_1 = results[0,:,:,0]\n",
    "img_2 = results[1,:,:,0]\n",
    "img_3 = results[2,:,:,0]\n",
    "img_4 = results[3,:,:,0]\n",
    "img_5 = results[4,:,:,0]\n",
    "img_6 = results[5,:,:,0]\n",
    "img_7 = results[6,:,:,0]\n",
    "img_8 = results[7,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# fig2, ax2 = plt.subplots(2,1,figsize=(8,14))\n",
    "# ax2[0].imshow(X_test[-8,:,:])\n",
    "# ax2[1].imshow(resize(img_1,(b1,c1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "labeled_img_1 = label(resize(img_1,(b1,c1)) > 0.5)\n",
    "labeled_img_2 = label(resize(img_2,(b1,c1)) > 0.5)\n",
    "labeled_img_3 = label(resize(img_3,(b1,c1)) > 0.5)\n",
    "labeled_img_4 = label(resize(img_4,(b1,c1)) > 0.5)\n",
    "labeled_img_5 = label(resize(img_5,(b1,c1)) > 0.5)\n",
    "labeled_img_6 = label(resize(img_6,(b1,c1)) > 0.5)\n",
    "labeled_img_7 = label(resize(img_7,(b1,c1)) > 0.5)\n",
    "labeled_img_8 = label(resize(img_8,(b1,c1)) > 0.5)\n",
    "\n",
    "regions_1 = regionprops(labeled_img_1)\n",
    "regions_2 = regionprops(labeled_img_2)\n",
    "regions_3 = regionprops(labeled_img_3)\n",
    "regions_4 = regionprops(labeled_img_4)\n",
    "regions_5 = regionprops(labeled_img_5)\n",
    "regions_6 = regionprops(labeled_img_6)\n",
    "regions_7 = regionprops(labeled_img_7)\n",
    "regions_8 = regionprops(labeled_img_8)\n",
    "regions_total = [regions_1, regions_2, regions_3, regions_4,\n",
    "                 regions_5, regions_6, regions_7, regions_8]\n",
    "\n",
    "fig3, ax3 = plt.subplots(4,2,figsize=(15,30))\n",
    "ax3 = np.ravel(ax3)\n",
    "for k1, k2 in enumerate(num_list):\n",
    "    ax3[k1].imshow(X_test[k2,:,:])\n",
    "\n",
    "i0 = np.array([0]*8)\n",
    "\n",
    "for k, region_l in enumerate(regions_total):\n",
    "    for i, j in enumerate(region_l):\n",
    "        if j.area > 30:\n",
    "            ax3[k].plot(j.centroid[1], j.centroid[0], 'r+')\n",
    "            i0[k] = i0[k] + 1\n",
    "\n",
    "for k in range(8):\n",
    "    ax3[k].set_title((\"number of cells = \"+str(i0[k])))\n",
    "    \n",
    "fig3.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
